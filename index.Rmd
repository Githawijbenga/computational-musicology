---
title: "Is there a difference between Nigerian an Ghananian afrobeats songs?"
author: "Githa Wijbenga"
output: 
  flexdashboard::flex_dashboard:
    storyboard: true
---

```{r, setup}
library(tidyverse)
library(plotly)
library(spotifyr)
library(compmus)
library(flexdashboard)
```

### Corpus

Afrobeats is a music genre originated from West Africa. More specifically from Nigeria and Ghana. It was very popular in the 2000's and 2010's. The artists sing mostly in Nigerian or Ghanaian accented English, or in the languages originated from these countries. Afrobeats is also called afropop or afrofusion. It's a fusion of different genres like dancehall, R&B, hip hop, etc. I think this genre is very interesting because the songs have an unique sound, and reflect the culture and history of West Africa. It's fairly new that people from all over the world listen to this music.

Other than the languages spoken in the song I'm interested to look for other differences between Nigerian and Ghanaian songs. I want to look for the unique influences and cultural heritage of each country in the different songs. Popular Nigerian artists are Wizkid, Tems and Burna Boy. Stonebwoy and Gyakie are examples of Ghanian singers. I'm going to use playlists with afrobeats music originated from both these countries. These playlists covers the Afrobeats genre well, but there are probably songs in it from artists who aren't originally from Nigeria or Ghana.

'Higher' from Tems, a Nigerian singer, is a slow song, which seems to sound like 'SOMETHING' from Gyakie, a Ghanian singer. These songs from these two women, are very typical for the afrobeats genre. It's interesting to compare these two songs and look for differences and similarities.

### Danceability and tempo


```{r}
ghana <- get_playlist_audio_features("","37i9dQZF1DX3zd1ZTQB0K9?si=71424602f1f446bf")
nigeria <- get_playlist_audio_features("", "5oLoDUUcDfJPfMXuwXMiXb?si=b5454940a9914127")

ghana_nigeria <-
  bind_rows(
    ghana |> mutate(category = "Ghana"),
    nigeria |> mutate(category = "Nigeria")
  )

hoi <- ghana_nigeria |>                   
  ggplot(aes(x = tempo, y = danceability, colour = energy,label = track.name)) + 
  geom_point(size=2.5) +
  geom_rug(linewidth = 0.1) + 
  facet_wrap(~ category) + 
  scale_x_continuous(limits = c(50, 200), breaks = c(50, 100, 200), minor_breaks = NULL) +
  scale_y_continuous(limits = c(0.4, 1),breaks = c(0.4, 0.7, 1),minor_breaks = NULL) +
  scale_colour_viridis_c(option = "E",alpha = 0.8,guide = "none") + 
  scale_size_continuous(guide = "none") +
  theme_light() + labs(x = "Tempo", y = "Dancability",colour = "Energy")

ggplotly(hoi)

```

***

The plot I made is comparing the tempo and danceability of songs on the x and y axis. Also it's showing the energy of songs with colour. It's interesting to see how Ghanian songs are more scattered over the x axis, which means the tempo is different for every song. The tempo of Nigerian songs are more similar to eachother. It's also interesting to look if tempo and dancebility are depended variables, because intuitively it is.

### Chromagram

```{r}
nigeria_song <-
  get_tidy_audio_analysis("0EYxr62cSeDetJKoIBaPbq") |>
  select(segments) |>
  unnest(segments) |>
  select(start, duration, pitches)

nigeria_song |>
  mutate(pitches = map(pitches, compmus_normalise, "euclidean")) |>
  compmus_gather_chroma() |> 
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = pitch_class,
      fill = value
    )
  ) +
  geom_tile() +
  ggtitle("Nigeria") +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
  theme_minimal() +
  scale_fill_viridis_c()

ghana_song <-
  get_tidy_audio_analysis("7fOjvfsHsPQt0Tlyd5douJ") |>
  select(segments) |>
  unnest(segments) |>
  select(start, duration, pitches)

ghana_song |>
  mutate(pitches = map(pitches, compmus_normalise, "euclidean")) |>
  compmus_gather_chroma() |> 
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = pitch_class,
      fill = value
    )
  ) +
  geom_tile() +
  ggtitle("Ghana") +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
  theme_minimal() +
  scale_fill_viridis_c()

```


***
The tempo of the music from the two different countries is different. To compare this, I took the median from both playlists and made a chromagram of it. The name of the nigerian song with median tempo is Fuku. The ghanaian one is called Hamba Haa. it is interesting to see that the songs are built up very differently. the pitches in Hamba Haa are much more spread out than those in Fuku. You can also clearly see that the tones are lower in Fuku. It can also be seen that there is a change after 100 seconds in Fuku. This can also be heard in the song.

<iframe src="https://open.spotify.com/track/0EYxr62cSeDetJKoIBaPbq" width="100%" height="380" frameBorder="0" allowfullscreen="" allow="autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture"></iframe>


### Chroma and timbre

```{r}
song <-
  get_tidy_audio_analysis("0EYxr62cSeDetJKoIBaPbq") |>
  compmus_align(bars, segments) |>
  select(bars) |>
  unnest(bars) |>
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "acentre", norm = "manhattan"
      )
  ) |>
  mutate(
    timbre =
      map(segments,
        compmus_summarise, timbre,
        method = "mean"
      )
  )
bind_rows(
  song |> 
    compmus_self_similarity(pitches, "aitchison") |> 
    mutate(d = d / max(d), type = "Chroma"),
  song |> 
    compmus_self_similarity(timbre, "euclidean") |> 
    mutate(d = d / max(d), type = "Timbre")
) |>
  mutate() |> 
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_fixed() +
  facet_wrap(~type) +
  scale_fill_viridis_c(option = "E", guide = "none") +
  theme_classic() + 
  labs(x = "", y = "")
```

***
Due to the change in pitch seen in Fuku's chromagram, I've decided to use chroma-based and timbre-based self-similarity matrices on this song. 



### Chordogram

```{r}
circshift <- function(v, n) {
  if (n == 0) v else c(tail(v, n), head(v, -n))
}

#      C     C#    D     Eb    E     F     F#    G     Ab    A     Bb    B
major_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    0,    0)
minor_chord <-
  c(   1,    0,    0,    1,    0,    0,    0,    1,    0,    0,    0,    0)
seventh_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    1,    0)

major_key <-
  c(6.35, 2.23, 3.48, 2.33, 4.38, 4.09, 2.52, 5.19, 2.39, 3.66, 2.29, 2.88)
minor_key <-
  c(6.33, 2.68, 3.52, 5.38, 2.60, 3.53, 2.54, 4.75, 3.98, 2.69, 3.34, 3.17)

chord_templates <-
  tribble(
    ~name, ~template,
    "Gb:7", circshift(seventh_chord, 6),
    "Gb:maj", circshift(major_chord, 6),
    "Bb:min", circshift(minor_chord, 10),
    "Db:maj", circshift(major_chord, 1),
    "F:min", circshift(minor_chord, 5),
    "Ab:7", circshift(seventh_chord, 8),
    "Ab:maj", circshift(major_chord, 8),
    "C:min", circshift(minor_chord, 0),
    "Eb:7", circshift(seventh_chord, 3),
    "Eb:maj", circshift(major_chord, 3),
    "G:min", circshift(minor_chord, 7),
    "Bb:7", circshift(seventh_chord, 10),
    "Bb:maj", circshift(major_chord, 10),
    "D:min", circshift(minor_chord, 2),
    "F:7", circshift(seventh_chord, 5),
    "F:maj", circshift(major_chord, 5),
    "A:min", circshift(minor_chord, 9),
    "C:7", circshift(seventh_chord, 0),
    "C:maj", circshift(major_chord, 0),
    "E:min", circshift(minor_chord, 4),
    "G:7", circshift(seventh_chord, 7),
    "G:maj", circshift(major_chord, 7),
    "B:min", circshift(minor_chord, 11),
    "D:7", circshift(seventh_chord, 2),
    "D:maj", circshift(major_chord, 2),
    "F#:min", circshift(minor_chord, 6),
    "A:7", circshift(seventh_chord, 9),
    "A:maj", circshift(major_chord, 9),
    "C#:min", circshift(minor_chord, 1),
    "E:7", circshift(seventh_chord, 4),
    "E:maj", circshift(major_chord, 4),
    "G#:min", circshift(minor_chord, 8),
    "B:7", circshift(seventh_chord, 11),
    "B:maj", circshift(major_chord, 11),
    "D#:min", circshift(minor_chord, 3)
  )

key_templates <-
  tribble(
    ~name, ~template,
    "Gb:maj", circshift(major_key, 6),
    "Bb:min", circshift(minor_key, 10),
    "Db:maj", circshift(major_key, 1),
    "F:min", circshift(minor_key, 5),
    "Ab:maj", circshift(major_key, 8),
    "C:min", circshift(minor_key, 0),
    "Eb:maj", circshift(major_key, 3),
    "G:min", circshift(minor_key, 7),
    "Bb:maj", circshift(major_key, 10),
    "D:min", circshift(minor_key, 2),
    "F:maj", circshift(major_key, 5),
    "A:min", circshift(minor_key, 9),
    "C:maj", circshift(major_key, 0),
    "E:min", circshift(minor_key, 4),
    "G:maj", circshift(major_key, 7),
    "B:min", circshift(minor_key, 11),
    "D:maj", circshift(major_key, 2),
    "F#:min", circshift(minor_key, 6),
    "A:maj", circshift(major_key, 9),
    "C#:min", circshift(minor_key, 1),
    "E:maj", circshift(major_key, 4),
    "G#:min", circshift(minor_key, 8),
    "B:maj", circshift(major_key, 11),
    "D#:min", circshift(minor_key, 3)
  )


song2 <-
  get_tidy_audio_analysis("0EYxr62cSeDetJKoIBaPbq") |>
  compmus_align(sections, segments) |>
  select(sections) |>
  unnest(sections) |>
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "mean", norm = "manhattan"
      )
  )

song2 |> 
  compmus_match_pitch_template(
    key_templates,         # Change to chord_templates if descired
    method = "euclidean",  # Try different distance metrics
    norm = "manhattan"     # Try different norms
  ) |>
  ggplot(
    aes(x = start + duration / 2, width = duration, y = name, fill = d)
  ) +
  geom_tile() +
  scale_fill_viridis_c(guide = "none") +
  theme_minimal() +
  labs(x = "Time (s)", y = "")

```

***
This is a keygram, also from the song Fuku. Here you can also see that after 100 seconds there is a big line, where the song changes key

### Conclusion and discussion





